{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "import re\n",
    "from itertools import chain\n",
    "from sklearn.utils import shuffle\n",
    "import nltk  \n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_romanian_data():\n",
    "    wb = load_workbook('../articole.xlsx')\n",
    "    sheet = wb['Foaie1']\n",
    "    data_pos=[]\n",
    "    data_neg=[]\n",
    "    data_doubt=[]\n",
    "    value = ''\n",
    "    for i in range(1, len(sheet['B'])):\n",
    "        value = str(sheet['B' + str(i)].value).replace('â€¢', '') # remove special characters\n",
    "        if bool(re.match('^(?=.*[a-zA-Z])', str(sheet['B' + str(i)].value))): # check if string not empty and has letters\n",
    "            if sheet['A' + str(i)].value == 1:\n",
    "                data_pos.append(value)\n",
    "            elif sheet['A' + str(i)].value == 0:\n",
    "                data_doubt.append(value)\n",
    "            elif not sheet['A' + str(i)].value:\n",
    "                data_neg.append(value)\n",
    "    print(\"data pos len: \" + str(len(data_pos)))\n",
    "    print( \"data neg len: \" + str(len(data_neg)))\n",
    "    \n",
    "#     low_limit = 3000\n",
    "#     high_limit = 10000\n",
    "#     test_pos = data_pos[:low_limit]\n",
    "#     train_pos = data_pos[low_limit:high_limit]\n",
    "#     test_neg = data_neg[:low_limit]\n",
    "    limit = 2400\n",
    "    test_pos = data_pos[:limit]\n",
    "    test_neg = data_neg[:limit]\n",
    "#     train_pos = data_pos[limit:]\n",
    "#     train_neg = data_neg[limit:len(data_pos)] # we make sure len of neg data = len of pos data(len neg > len pos initially)\n",
    "\n",
    "#     train_pos = [str(w).lower() for w in train_pos]\n",
    "#     train_pos = ([\" \".join(j for j in w.split() if len(j) >= 2) for w in train_pos])\n",
    "\n",
    "#     train_neg = [str(w).lower() for w in train_neg]\n",
    "#     train_neg = ([\" \".join(j for j in w.split() if len(j) >= 2) for w in train_neg])\n",
    "\n",
    "    with open(\"data/lemma/train_pos_lemma.txt\") as pos_lemma:\n",
    "        train_pos_lemma = pos_lemma.readlines()\n",
    "    train_pos_lemma = ([\" \".join(j for j in w.split() if len(j) >= 2) for w in train_pos_lemma])\n",
    "    with open(\"data/lemma/train_neg_lemma.txt\") as neg_lemma:\n",
    "        train_neg_lemma = neg_lemma.readlines()\n",
    "    train_neg_lemma = ([\" \".join(j for j in w.split() if len(j) >= 2) for w in train_neg_lemma])\n",
    "    \n",
    "    test_pos = [str(w).lower() for w in test_pos]\n",
    "    test_neg = [str(w).lower() for w in test_neg]\n",
    "    \n",
    "    return train_pos_lemma, train_neg_lemma, test_pos, test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_and_test(train_pos, train_neg, test_pos, test_neg):\n",
    "    X_train = list(chain(train_pos, train_neg))\n",
    "    y_train = np.concatenate((np.ones(len(train_pos), int), np.zeros(len(train_neg), int)))\n",
    "\n",
    "    X_test = list(chain(test_pos, test_neg))\n",
    "    y_test = np.concatenate((np.ones(len(test_pos), int), np.zeros(len(test_neg), int)))\n",
    "\n",
    "    X_train_shuffled, y_train_shuffled =  shuffle(X_train, y_train)\n",
    "    X_test_shuffled, y_test_shuffled = shuffle(X_test, y_test)\n",
    "\n",
    "    return X_train_shuffled, y_train_shuffled, X_test_shuffled, y_test_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sentences_list, updated_stopwords):\n",
    "    filtered_sentence = []\n",
    "    for sentence in sentences_list:\n",
    "        filtered_sentence.append([w for w in sentence if not w in updated_stopwords])\n",
    "    return repair_sentence(filtered_sentence)\n",
    "\n",
    "\n",
    "def remove_punctuation(from_train_data):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    no_punctuation = [w.translate(table) for w in from_train_data]\n",
    "    numbers = re.compile('[0-9]')\n",
    "    plain_text = [numbers.sub(\"\", word) for word in no_punctuation]\n",
    "    return plain_text\n",
    "    \n",
    "\n",
    "def remove_spaces(from_train_data):\n",
    "    clean_spaces_data = []\n",
    "    for sentence in from_train_data:\n",
    "        clean_spaces_data.append(re.sub(' +', ' ', sentence).rstrip().lstrip())\n",
    "    return clean_spaces_data\n",
    "\n",
    "def repair_sentence(sentence_list):\n",
    "    return [' '.join(map(str, element)) for element in sentence_list]\n",
    "\n",
    "\n",
    "def update_stopwords(stopwords):\n",
    "    do_no_remove_these_sw = ['not', 'no', 'can','has','have','had','must','shan','do', 'should','was','were','won',\n",
    "                             'are','cannot','does','ain', 'could', 'did', 'is', 'might', 'need', 'would']\n",
    "    return [word for word in stopwords if word not in do_no_remove_these_sw]\n",
    "\n",
    "\n",
    "def stem_words(from_text):\n",
    "    stemmer = SnowballStemmer(\"romanian\")\n",
    "    stemmer2 = SnowballStemmer(\"romanian\", ignore_stopwords=True)\n",
    "    return [\" \".join([stemmer.stem(word) for word in sentence.split(\" \")]) for sentence in from_text]\n",
    "\n",
    "\n",
    "def lemmatize_words(sentence):\n",
    "    from pywsd.utils import lemmatize_sentence\n",
    "    return lemmatize_sentence(sentence)\n",
    "\n",
    "\n",
    "def sentence_tokenization(sentence):\n",
    "    return word_tokenize(sentence)\n",
    "\n",
    "\n",
    "def sentence_punct_tokenization(sentence):\n",
    "    return WordPunctTokenizer().tokenize(sentence)\n",
    "\n",
    "\n",
    "def sentence_split_tokenization(sentence):\n",
    "    return ([i for i in re.split(' ', sentence) if i])\n",
    "\n",
    "\n",
    "def remove_apostrophe_words(train):\n",
    "    train = [w.replace(\"it's\", 'it is')\n",
    "                     .replace(\"that's\", \"that is\")\n",
    "                     .replace(\"it 's\", 'it is')\n",
    "                     .replace(\"that 's\", \"that is\")\n",
    "                     .replace(\"'ve\", \" have\")\n",
    "                     .replace(\"' ve\", \" have\")\n",
    "                     .replace(\"won't\", \"will not\")\n",
    "                     .replace(\"wo n't\", \"will not\")\n",
    "                     .replace(\"don't\", \"do not\")\n",
    "                     .replace(\"do n't\", \"do not\")\n",
    "                     .replace(\"can't\", \"can not\")\n",
    "                     .replace(\"ca n't\", \"can not\")\n",
    "                     .replace(\"sha n't\", \"shall not\")\n",
    "                     .replace(\"shan't\", \"shall not\")\n",
    "                     .replace(\"n't\", \" not\")\n",
    "                     .replace(\"'re\", \" are\")\n",
    "                     .replace(\"'d\", \" would\")\n",
    "                     .replace(\"'ll\", \" will\") for w in train]\n",
    "    return train\n",
    "\n",
    "def remove_empty_sentences(X, y):\n",
    "    new_X = []\n",
    "    new_y = []\n",
    "    for i in range(len(X)):\n",
    "        if len(X[i].split()) > 1:\n",
    "            new_X.append(X[i])\n",
    "            new_y.append(y[i])\n",
    "    return new_X, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(X_train):\n",
    "    stopwords = set(nltk.corpus.stopwords.words('romanian'))\n",
    "    \n",
    "    tokenized_sentence = []\n",
    "    for sentence in X_train:\n",
    "        tokenized_sentence.append(sentence_punct_tokenization(sentence))\n",
    "\n",
    "    # NO STOP WORDS\n",
    "    train_without_stopwords = remove_stopwords(tokenized_sentence, stopwords)\n",
    "\n",
    "    # NO PUNCTUATION\n",
    "    train_without_punctuation = remove_punctuation(train_without_stopwords)\n",
    "    train_clean_spaces = remove_spaces(train_without_punctuation)\n",
    "    return train_clean_spaces # we choose to extract stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data pos len: 11077\n",
      "data neg len: 23509\n"
     ]
    }
   ],
   "source": [
    "train_pos, train_neg, test_pos, test_neg = load_romanian_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = prepare_train_and_test(train_pos, train_neg, test_pos, test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_train = feature(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=80, random_state=13)\n",
    "svm_clf = svm.SVC(gamma='scale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_bigram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(2, 2))\n",
    "# counts = ngram_vectorizer.fit_transform(['words', 'wprds'])\n",
    "X_train_char_bigrams = char_bigram_vectorizer.fit_transform(X_train)\n",
    "X_test_char_bigrams = char_bigram_vectorizer.fit_transform(X_test)\n",
    "# ngram_vectorizer.get_feature_names() == (\n",
    "#     [' w', 'ds', 'or', 'pr', 'rd', 's ', 'wo', 'wp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LSI model and perform dimensionality reduction\n",
    "X_train_char_bigrams_reduced = svd.fit_transform(X_train_char_bigrams)\n",
    "X_test_char_bigrams_reduced = svd.fit_transform(X_test_char_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Character 2-grams (SVM) ==========\n",
      "The F-1 score for test query is 0.7057252282262025\n",
      "Training accuracy of SVM model is 0.7214179870055853\n",
      "Test accuracy of SVM model is 0.7058333333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Support Vector Machine\n",
    "svm_clf = svm.SVC(gamma='scale')\n",
    "svm_clf.fit(X_train_char_bigrams_reduced, y_train)\n",
    "\n",
    "predicted_test = svm_clf.predict(X_test_char_bigrams_reduced)\n",
    "predicted_train = svm_clf.predict(X_train_char_bigrams_reduced)\n",
    "\n",
    "print('========== Character 2-grams (SVM) ==========')\n",
    "print('The F-1 score for test query is ' + str(metrics.f1_score(y_test, predicted_test, average = 'macro')))\n",
    "print('Training accuracy of SVM model is ' + str(np.mean(predicted_train == y_train)))\n",
    "print('Test accuracy of SVM model is ' + str(np.mean(predicted_test == y_test)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------------------\n",
      "Roc auc:  0.7058333333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC + AUC\n",
    "# y_predict_proba = model.predict_proba(X_test)\n",
    "probabilities = np.array(predicted_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('-----------------------------------------------------------------------------------------------------------')\n",
    "print('Roc auc: ', roc_auc)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "char_trigram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(3, 3))\n",
    "X_train_char_trigrams = char_trigram_vectorizer.fit_transform(X_train)\n",
    "X_test_char_trigrams = char_trigram_vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LSI model and perform dimensionality reduction\n",
    "X_train_char_trigrams_reduced = svd.fit_transform(X_train_char_trigrams)\n",
    "X_test_char_trigrams_reduced = svd.fit_transform(X_test_char_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Character 3-grams (SVM) ==========\n",
      "The F-1 score for test query is 0.5192217299197985\n",
      "Training accuracy of SVM model is 0.741593525589878\n",
      "Test accuracy of SVM model is 0.5727083333333334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Support Vector Machine\n",
    "svm_clf.fit(X_train_char_trigrams_reduced, y_train)\n",
    "\n",
    "predicted_test = svm_clf.predict(X_test_char_trigrams_reduced)\n",
    "predicted_train = svm_clf.predict(X_train_char_trigrams_reduced)\n",
    "\n",
    "print('========== Character 3-grams (SVM) ==========')\n",
    "print('The F-1 score for test query is ' + str(metrics.f1_score(y_test, predicted_test, average = 'macro')))\n",
    "print('Training accuracy of SVM model is ' + str(np.mean(predicted_train == y_train)))\n",
    "print('Test accuracy of SVM model is ' + str(np.mean(predicted_test == y_test)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character 4-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 2, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [4, 1, 1, ..., 0, 0, 0],\n",
       "       [2, 0, 4, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_4gram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(4, 4))\n",
    "X_train_char_4grams = char_4gram_vectorizer.fit_transform(X_train)\n",
    "X_test_char_4grams = char_4gram_vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LSI model and perform dimensionality reduction\n",
    "X_train_char_4grams_reduced = svd.fit_transform(X_train_char_4grams)\n",
    "X_test_char_4grams_reduced = svd.fit_transform(X_test_char_4grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Support Vector Machine ==========\n",
      "The F-1 score for test query is 0.5014245014245013\n",
      "Training accuracy of SVM model is 0.7282571526273794\n",
      "Test accuracy of SVM model is 0.5625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Support Vector Machine\n",
    "svm_clf = svm.SVC(gamma='scale')\n",
    "svm_clf.fit(X_train_char_4grams_reduced, y_train)\n",
    "\n",
    "predicted_test = svm_clf.predict(X_test_char_4grams_reduced)\n",
    "predicted_train = svm_clf.predict(X_train_char_4grams_reduced)\n",
    "\n",
    "print('========== Character 4-grams (SVM) ==========')\n",
    "print('The F-1 score for test query is ' + str(metrics.f1_score(y_test, predicted_test, average = 'macro')))\n",
    "print('Training accuracy of SVM model is ' + str(np.mean(predicted_train == y_train)))\n",
    "print('Test accuracy of SVM model is ' + str(np.mean(predicted_test == y_test)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character 5-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 2, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [4, 1, 1, ..., 0, 0, 0],\n",
       "       [2, 0, 4, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_5gram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(5, 5))\n",
    "X_train_char_5grams = char_5gram_vectorizer.fit_transform(X_train)\n",
    "X_test_char_5grams = char_5gram_vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LSI model and perform dimensionality reduction\n",
    "X_train_char_5grams_reduced = svd.fit_transform(X_train_char_5grams)\n",
    "X_test_char_5grams_reduced = svd.fit_transform(X_test_char_5grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Character 5-grams (SVM) ==========\n",
      "The F-1 score for test query is 0.46976818940786447\n",
      "Training accuracy of SVM model is 0.7140658839621566\n",
      "Test accuracy of SVM model is 0.5489583333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Support Vector Machine\n",
    "svm_clf = svm.SVC(gamma='scale')\n",
    "svm_clf.fit(X_train_char_5grams_reduced, y_train)\n",
    "\n",
    "predicted_test = svm_clf.predict(X_test_char_5grams_reduced)\n",
    "predicted_train = svm_clf.predict(X_train_char_5grams_reduced)\n",
    "\n",
    "print('========== Character 5-grams (SVM) ==========')\n",
    "print('The F-1 score for test query is ' + str(metrics.f1_score(y_test, predicted_test, average = 'macro')))\n",
    "print('Training accuracy of SVM model is ' + str(np.mean(predicted_train == y_train)))\n",
    "print('Test accuracy of SVM model is ' + str(np.mean(predicted_test == y_test)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character 6-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 2, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [4, 1, 1, ..., 0, 0, 0],\n",
       "       [2, 0, 4, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_6gram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(6, 6))\n",
    "X_train_char_6grams = char_6gram_vectorizer.fit_transform(X_train)\n",
    "X_test_char_6grams = char_6gram_vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LSI model and perform dimensionality reduction\n",
    "X_train_char_6grams_reduced = svd.fit_transform(X_train_char_6grams)\n",
    "X_test_char_6grams_reduced = svd.fit_transform(X_test_char_6grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Character 5-grams (SVM) ==========\n",
      "The F-1 score for test query is 0.46976818940786447\n",
      "Training accuracy of SVM model is 0.7140658839621566\n",
      "Test accuracy of SVM model is 0.5489583333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Support Vector Machine\n",
    "svm_clf = svm.SVC(gamma='scale')\n",
    "svm_clf.fit(X_train_char_6grams_reduced, y_train)\n",
    "\n",
    "predicted_test = svm_clf.predict(X_test_char_6grams_reduced)\n",
    "predicted_train = svm_clf.predict(X_train_char_6grams_reduced)\n",
    "\n",
    "print('========== Character 6-grams (SVM) ==========')\n",
    "print('The F-1 score for test query is ' + str(metrics.f1_score(y_test, predicted_test, average = 'macro')))\n",
    "print('Training accuracy of SVM model is ' + str(np.mean(predicted_train == y_train)))\n",
    "print('Test accuracy of SVM model is ' + str(np.mean(predicted_test == y_test)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character 7-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 2, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [4, 1, 1, ..., 0, 0, 0],\n",
       "       [2, 0, 4, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_7gram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(7, 7))\n",
    "X_train_char_7grams = char_7gram_vectorizer.fit_transform(X_train)\n",
    "X_test_char_7grams = char_7gram_vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LSI model and perform dimensionality reduction\n",
    "X_train_char_7grams_reduced = svd.fit_transform(X_train_char_7grams)\n",
    "X_test_char_7grams_reduced = svd.fit_transform(X_test_char_7grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Support Vector Machine\n",
    "svm_clf = svm.SVC(gamma='scale')\n",
    "svm_clf.fit(X_train_char_7grams_reduced, y_train)\n",
    "\n",
    "predicted_test = svm_clf.predict(X_test_char_7grams_reduced)\n",
    "predicted_train = svm_clf.predict(X_train_char_7grams_reduced)\n",
    "\n",
    "print('========== Character 7-grams (SVM) ==========')\n",
    "print('The F-1 score for test query is ' + str(metrics.f1_score(y_test, predicted_test, average = 'macro')))\n",
    "print('Training accuracy of SVM model is ' + str(np.mean(predicted_train == y_train)))\n",
    "print('Test accuracy of SVM model is ' + str(np.mean(predicted_test == y_test)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character 8-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 2, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [4, 1, 1, ..., 0, 0, 0],\n",
       "       [2, 0, 4, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_8gram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(8, 8))\n",
    "X_train_char_8grams = char_8gram_vectorizer.fit_transform(X_train)\n",
    "X_test_char_8grams = char_8gram_vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LSI model and perform dimensionality reduction\n",
    "X_train_char_8grams_reduced = svd.fit_transform(X_train_char_8grams)\n",
    "X_test_char_8grams_reduced = svd.fit_transform(X_test_char_8grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Character 5-grams (SVM) ==========\n",
      "The F-1 score for test query is 0.46976818940786447\n",
      "Training accuracy of SVM model is 0.7140658839621566\n",
      "Test accuracy of SVM model is 0.5489583333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "svm_clf = svm.SVC(gamma='scale')\n",
    "svm_clf.fit(X_train_char_8grams_reduced, y_train)\n",
    "\n",
    "predicted_test = svm_clf.predict(X_test_char_8grams_reduced)\n",
    "predicted_train = svm_clf.predict(X_train_char_8grams_reduced)\n",
    "\n",
    "print('========== Character 8-grams (SVM) ==========')\n",
    "print('The F-1 score for test query is ' + str(metrics.f1_score(y_test, predicted_test, average = 'macro')))\n",
    "print('Training accuracy of SVM model is ' + str(np.mean(predicted_train == y_train)))\n",
    "print('Test accuracy of SVM model is ' + str(np.mean(predicted_test == y_test)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_unigram_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1))\n",
    "X_train_word_unigrams = word_unigram_vectorizer.fit_transform(X_train)\n",
    "X_test_word_unigrams = word_unigram_vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LSI model and perform dimensionality reduction\n",
    "X_train_word_unigrams_reduced = svd.fit_transform(X_train_word_unigrams)\n",
    "X_test_word_unigrams_reduced = svd.fit_transform(X_test_word_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Character 5-grams (SVM) ==========\n",
      "The F-1 score for test query is 0.6314399701297755\n",
      "Training accuracy of SVM model is 0.7387438732474638\n",
      "Test accuracy of SVM model is 0.63875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "svm_clf = svm.SVC(gamma='scale')\n",
    "svm_clf.fit(X_train_word_unigrams_reduced, y_train)\n",
    "\n",
    "predicted_test = svm_clf.predict(X_test_word_unigrams_reduced)\n",
    "predicted_train = svm_clf.predict(X_train_word_unigrams_reduced)\n",
    "\n",
    "print('========== Word unigrams (SVM) ==========')\n",
    "print('The F-1 score for test query is ' + str(metrics.f1_score(y_test, predicted_test, average = 'macro')))\n",
    "print('Training accuracy of SVM model is ' + str(np.mean(predicted_train == y_train)))\n",
    "print('Test accuracy of SVM model is ' + str(np.mean(predicted_test == y_test)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_bigram_vectorizer = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "X_train_word_bigrams = word_bigram_vectorizer.fit_transform(X_train)\n",
    "X_test_word_bigrams = word_bigram_vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LSI model and perform dimensionality reduction\n",
    "X_train_word_bigrams_reduced = svd.fit_transform(X_train_word_bigrams)\n",
    "X_test_word_bigrams_reduced = svd.fit_transform(X_test_word_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Character 5-grams (SVM) ==========\n",
      "The F-1 score for test query is 0.6314399701297755\n",
      "Training accuracy of SVM model is 0.7387438732474638\n",
      "Test accuracy of SVM model is 0.63875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "svm_clf = svm.SVC(gamma='scale')\n",
    "svm_clf.fit(X_train_word_bigrams_reduced, y_train)\n",
    "\n",
    "predicted_test = svm_clf.predict(X_test_word_bigrams_reduced)\n",
    "predicted_train = svm_clf.predict(X_train_word_bigrams_reduced)\n",
    "\n",
    "print('========== Word bigrams (SVM) ==========')\n",
    "print('The F-1 score for test query is ' + str(metrics.f1_score(y_test, predicted_test, average = 'macro')))\n",
    "print('Training accuracy of SVM model is ' + str(np.mean(predicted_train == y_train)))\n",
    "print('Test accuracy of SVM model is ' + str(np.mean(predicted_test == y_test)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_trigram_vectorizer = CountVectorizer(analyzer='word', ngram_range=(3, 3))\n",
    "X_train_word_trigrams = word_trigram_vectorizer.fit_transform(X_train)\n",
    "X_test_word_trigrams = word_trigram_vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LSI model and perform dimensionality reduction\n",
    "X_train_word_trigrams_reduced = svd.fit_transform(X_train_word_trigrams)\n",
    "X_test_word_trigrams_reduced = svd.fit_transform(X_test_word_trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 82789 should be equal to 280703, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-8e470292972d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_word_trigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredicted_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_word_trigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpredicted_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_word_trigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \"\"\"\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    472\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[1;32m    473\u001b[0m                              \u001b[0;34m\"the number of features at training time\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                              (n_features, self.shape_fit_[1]))\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X.shape[1] = 82789 should be equal to 280703, the number of features at training time"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "svm_clf = svm.SVC(gamma='scale')\n",
    "svm_clf.fit(X_train_word_trigrams, y_train)\n",
    "\n",
    "predicted_test = svm_clf.predict(X_test_word_trigrams)\n",
    "predicted_train = svm_clf.predict(X_train_word_trigrams)\n",
    "\n",
    "print('========== Word trigrams (SVM) ==========')\n",
    "print('The F-1 score for test query is ' + str(metrics.f1_score(y_test, predicted_test, average = 'macro')))\n",
    "print('Training accuracy of SVM model is ' + str(np.mean(predicted_train == y_train)))\n",
    "print('Test accuracy of SVM model is ' + str(np.mean(predicted_test == y_test)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz import itertoolz, compose\n",
    "from toolz.curried import map as cmap, sliding_window, pluck\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneSkipBigramVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):    \n",
    "        preprocess = self.build_preprocessor()\n",
    "        stop_words = self.get_stop_words()\n",
    "        tokenize = self.build_tokenizer()\n",
    "        return lambda doc: self._word_skip_grams(\n",
    "                compose(tokenize, preprocess, self.decode)(doc),\n",
    "                stop_words)\n",
    "\n",
    "    def _word_skip_grams(self, tokens, stop_words=None):\n",
    "        # handle stop words\n",
    "        if stop_words is not None:\n",
    "            tokens = [w for w in tokens if w not in stop_words]\n",
    "\n",
    "        return compose(cmap(' '.join), pluck([0, 2]), sliding_window(3))(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoSkipBigramVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):    \n",
    "        preprocess = self.build_preprocessor()\n",
    "        stop_words = self.get_stop_words()\n",
    "        tokenize = self.build_tokenizer()\n",
    "        return lambda doc: self._word_skip_grams(\n",
    "                compose(tokenize, preprocess, self.decode)(doc),\n",
    "                stop_words)\n",
    "\n",
    "    def _word_skip_grams(self, tokens, stop_words=None):\n",
    "        # handle stop words\n",
    "        if stop_words is not None:\n",
    "            tokens = [w for w in tokens if w not in stop_words]\n",
    "\n",
    "        return compose(cmap(' '.join), pluck([0, 3]), sliding_window(4))(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeSkipBigramVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):    \n",
    "        preprocess = self.build_preprocessor()\n",
    "        stop_words = self.get_stop_words()\n",
    "        tokenize = self.build_tokenizer()\n",
    "        return lambda doc: self._word_skip_grams(\n",
    "                compose(tokenize, preprocess, self.decode)(doc),\n",
    "                stop_words)\n",
    "\n",
    "    def _word_skip_grams(self, tokens, stop_words=None):\n",
    "        # handle stop words\n",
    "        if stop_words is not None:\n",
    "            tokens = [w for w in tokens if w not in stop_words]\n",
    "\n",
    "        return compose(cmap(' '.join), pluck([0, 4]), sliding_window(5))(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-skip bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_skip_bigram_vectorizer = OneSkipBigramVectorizer()\n",
    "# vect.fit(X_train)\n",
    "X_train_one_skip_bigrams = one_skip_bigram_vectorizer.fit_transform(X_train)\n",
    "X_test_one_skip_bigrams = one_skip_bigram_vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LSI model and perform dimensionality reduction\n",
    "X_train_one_skip_bigrams_reduced = svd.fit_transform(X_train_one_skip_bigrams)\n",
    "X_test_one_skip_bigrams_reduced = svd.fit_transform(X_test_one_skip_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Word trigrams (SVM) ==========\n",
      "The F-1 score for test query is 0.5604783092032326\n",
      "Training accuracy of SVM model is 0.7071127322466659\n",
      "Test accuracy of SVM model is 0.5864583333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "svm_clf = svm.SVC(gamma='scale')\n",
    "svm_clf.fit(X_train_one_skip_bigrams_reduced, y_train)\n",
    "\n",
    "predicted_test = svm_clf.predict(X_test_one_skip_bigrams_reduced)\n",
    "predicted_train = svm_clf.predict(X_train_one_skip_bigrams_reduced)\n",
    "\n",
    "print('========== 1-skip bigrams (SVM) ==========')\n",
    "print('The F-1 score for test query is ' + str(metrics.f1_score(y_test, predicted_test, average = 'macro')))\n",
    "print('Training accuracy of SVM model is ' + str(np.mean(predicted_train == y_train)))\n",
    "print('Test accuracy of SVM model is ' + str(np.mean(predicted_test == y_test)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-skip bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_skip_bigram_vectorizer = TwoSkipBigramVectorizer()\n",
    "# vect.fit(X_train)\n",
    "X_train_two_skip_bigrams = two_skip_bigram_vectorizer.fit_transform(X_train)\n",
    "X_test_two_skip_bigrams = two_skip_bigram_vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LSI model and perform dimensionality reduction\n",
    "X_train_two_skip_bigrams_reduced = svd.fit_transform(X_train_two_skip_bigrams)\n",
    "X_test_two_skip_bigrams_reduced = svd.fit_transform(X_test_two_skip_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Word trigrams (SVM) ==========\n",
      "The F-1 score for test query is 0.5810189134250331\n",
      "Training accuracy of SVM model is 0.7059728713097002\n",
      "Test accuracy of SVM model is 0.5975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "svm_clf = svm.SVC(gamma='scale')\n",
    "svm_clf.fit(X_train_two_skip_bigrams_reduced, y_train)\n",
    "\n",
    "predicted_test = svm_clf.predict(X_test_two_skip_bigrams_reduced)\n",
    "predicted_train = svm_clf.predict(X_train_two_skip_bigrams_reduced)\n",
    "\n",
    "print('========== 2-skip bigrams (SVM) ==========')\n",
    "print('The F-1 score for test query is ' + str(metrics.f1_score(y_test, predicted_test, average = 'macro')))\n",
    "print('Training accuracy of SVM model is ' + str(np.mean(predicted_train == y_train)))\n",
    "print('Test accuracy of SVM model is ' + str(np.mean(predicted_test == y_test)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-skip bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_skip_bigram_vectorizer = ThreeSkipBigramVectorizer()\n",
    "# vect.fit(X_train)\n",
    "X_train_three_skip_bigrams = three_skip_bigram_vectorizer.fit_transform(X_train)\n",
    "X_test_three_skip_bigrams = three_skip_bigram_vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LSI model and perform dimensionality reduction\n",
    "X_train_three_skip_bigrams_reduced = svd.fit_transform(X_train_three_skip_bigrams)\n",
    "X_test_three_skip_bigrams_reduced = svd.fit_transform(X_test_three_skip_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Word trigrams (SVM) ==========\n",
      "The F-1 score for test query is 0.5832349984703467\n",
      "Training accuracy of SVM model is 0.7022113302177134\n",
      "Test accuracy of SVM model is 0.5964583333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "svm_clf = svm.SVC(gamma='scale')\n",
    "svm_clf.fit(X_train_three_skip_bigrams_reduced, y_train)\n",
    "\n",
    "predicted_test = svm_clf.predict(X_test_three_skip_bigrams_reduced)\n",
    "predicted_train = svm_clf.predict(X_train_three_skip_bigrams_reduced)\n",
    "\n",
    "print('========== 3-skip bigrams (SVM) ==========')\n",
    "print('The F-1 score for test query is ' + str(metrics.f1_score(y_test, predicted_test, average = 'macro')))\n",
    "print('Training accuracy of SVM model is ' + str(np.mean(predicted_train == y_train)))\n",
    "print('Test accuracy of SVM model is ' + str(np.mean(predicted_test == y_test)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_vectorizer = CountVectorizer(analyzer='word', ngram_range=(3, 3))\n",
    "X_train_all_features = all_features_vectorizer.fit_transform(X_train)\n",
    "X_test_all_features = all_features_vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the LSI model and perform dimensionality reduction\n",
    "X_train_all_features_reduced = svd.fit_transform(X_train_all_features)\n",
    "X_test_all_features_reduced = svd.fit_transform(X_test_all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all_features_reduced.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Word trigrams (SVM) ==========\n",
      "The F-1 score for test query is 0.5124197211202561\n",
      "Training accuracy of SVM model is 0.6191724609597629\n",
      "Test accuracy of SVM model is 0.5604166666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine\n",
    "svm_clf = svm.SVC(gamma='scale')\n",
    "svm_clf.fit(X_train_all_features_reduced, y_train)\n",
    "\n",
    "predicted_test = svm_clf.predict(X_test_all_features_reduced)\n",
    "predicted_train = svm_clf.predict(X_train_all_features_reduced)\n",
    "\n",
    "print('========== Word trigrams (SVM) ==========')\n",
    "print('The F-1 score for test query is ' + str(metrics.f1_score(y_test, predicted_test, average = 'macro')))\n",
    "print('Training accuracy of SVM model is ' + str(np.mean(predicted_train == y_train)))\n",
    "print('Test accuracy of SVM model is ' + str(np.mean(predicted_test == y_test)))\n",
    "print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
